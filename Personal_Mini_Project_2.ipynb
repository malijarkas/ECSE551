{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rBoav8kOvPCH",
        "EzLd7uXk3lZN",
        "QzlY-Rt3D9BZ",
        "auFt597smEq6",
        "J43GCl1FmIMD",
        "ovQt8kl08ton"
      ],
      "mount_file_id": "1D2x-n5Jyxaaet4eTXGaqP7Oiy9fQ4glL",
      "authorship_tag": "ABX9TyN6GBW5N2ZN1DpqaXH9E6cf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malijarkas/ECSE551/blob/main/Personal_Mini_Project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount drive and import data"
      ],
      "metadata": {
        "id": "rBoav8kOvPCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "input_data_path = '/content/drive/My Drive/ECSE 551 Data Set/Train.csv'\n",
        "# test_data_path = '/content/drive/My Drive/ECSE 551 Data Set/Test.csv'\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "input_data = pd.read_csv(input_data_path, header=None)\n",
        "# test_data = pd.read_csv(test_data_path, header=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sYJL0E4jM9N",
        "outputId": "a595322a-1d8c-4ab1-a784-020c54ffab73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions"
      ],
      "metadata": {
        "id": "EzLd7uXk3lZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# writes string array to file with delimiter '\\n'\n",
        "def write_to_csv(output, file_name):\n",
        "  with open(file_name, 'w') as f:\n",
        "    for i in range(len(output)):\n",
        "      f.write(str(output[i]))\n",
        "      f.write('\\n')\n",
        "\n",
        "# Converts class names to indices, makes indexing in future operations easier\n",
        "# Takes in the Y label numpy array and outputs it indexed\n",
        "# The index values are dependant on the orders in class_names list\n",
        "def class_name_to_index(class_names, Y_label):\n",
        "    if not isinstance(Y_label, np.ndarray):\n",
        "        raise TypeError(\"Y must be a numpy array\")\n",
        "\n",
        "    Y_string = np.copy(Y_label) #to avoid modifying Y_label\n",
        "    Y_int = np.zeros(Y_string.size)\n",
        "\n",
        "    class_dict = {name: idx for idx, name in enumerate(class_names)}\n",
        "    for i in range(Y_string.size):\n",
        "        if Y_string[i] in class_dict:\n",
        "            Y_int[i] = class_dict[Y_string[i]]\n",
        "        else:\n",
        "            raise ValueError(f\"Unexpected class name '{Y_string[i]}' in Y\")\n",
        "    return np.array(Y_int)\n",
        "\n",
        "# Converts indices back to their class names\n",
        "# Takes in the same list of class names and the numpy array Y_integer\n",
        "def index_to_class_name(class_names, Y_index):\n",
        "  if not isinstance(Y_index, np.ndarray):\n",
        "    raise TypeError(\"Y_index must be a numpy array\")\n",
        "\n",
        "  Y_int = np.copy(Y_index)\n",
        "  Y_string = np.empty(Y_int.size, dtype=object)\n",
        "\n",
        "  if not (0 <= Y_int).all() and (Y_int < len(class_names)).all():\n",
        "      raise ValueError(\"Y_index parameter contains invalid class index\")\n",
        "\n",
        "  for i in range(Y_int.size):\n",
        "      Y_string[i] = class_names[int(Y_int[i])]\n",
        "  return Y_string\n",
        "\n",
        "def calculate_accuracy(predict_output, given_output):\n",
        "  error_count = 0\n",
        "  for i in range(predict_output.size):\n",
        "    if predict_output[i] != given_output[i]:\n",
        "      error_count += 1\n",
        "\n",
        "  return error_count / predict_output.shape[0]"
      ],
      "metadata": {
        "id": "2bOAqsel3n8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess data\n",
        "- try bigrams, trigrams...\n",
        "- try kaggle"
      ],
      "metadata": {
        "id": "377GdW14yDHu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### my implementation"
      ],
      "metadata": {
        "id": "-eVRfzF4fcD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "num_features = 3000\n",
        "class_list = ['Toronto', 'Montreal', 'London', 'Brussels']\n",
        "\n",
        "# partition data\n",
        "input_data_x = np.array(input_data[0])\n",
        "input_data_y = np.array(input_data[1])\n",
        "\n",
        "# tokenize the training data, set ngram_range\n",
        "vectorizer = CountVectorizer(max_features=num_features, binary=True, ngram_range=(2, 2))\n",
        "\n",
        "# convert input_data_x to binary\n",
        "input_data_x_b = vectorizer.fit_transform(input_data_x).todense()\n",
        "\n",
        "# map input data y labels to indices\n",
        "input_data_y_indexed = class_name_to_index(np.array(class_list), input_data_y)\n",
        "\n",
        "k_fold_test = 1\n",
        "\n",
        "if k_fold_test == True:\n",
        "  k_folds = 10\n",
        "  # k_fold\n",
        "  kf = KFold(n_splits=k_folds, shuffle=True, random_state=10)\n",
        "\n",
        "  X_train = np.array([None] * k_folds)\n",
        "  X_test = np.array([None] * k_folds)\n",
        "  Y_train = np.array([None] * k_folds)\n",
        "  Y_test = np.array([None] * k_folds)\n",
        "\n",
        "  for i, (train_index, test_index) in enumerate(kf.split(input_data_x_b)):\n",
        "    X_train[i], X_test[i] = np.array(input_data_x_b[train_index]), input_data_x_b[test_index]\n",
        "    Y_train[i], Y_test[i] = input_data_y_indexed[train_index], input_data_y_indexed[test_index]\n",
        "    # print(test_index[i])\n",
        "    # print(\"--------------------\")\n",
        "\n",
        "else:\n",
        "# train_test_split\n",
        "  X_train = np.array([None])\n",
        "  Y_train = np.array([None])\n",
        "  X_test = np.array([None])\n",
        "  Y_test = np.array([None])\n",
        "\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(input_data_x_b, input_data_y_indexed, test_size=0.1, random_state=10)"
      ],
      "metadata": {
        "id": "5wyEf8o6yHCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### henry's code"
      ],
      "metadata": {
        "id": "4LG7RnWVfgeV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vQt2FpQXfjZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### alpha_Naive Bayes Classifier\n",
        "\n",
        "TODO:\n",
        "- fix the fixme\n",
        "- another set of eyes to make sure its correct"
      ],
      "metadata": {
        "id": "QzlY-Rt3D9BZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "class Naive_Bayes_Classifier:\n",
        "\n",
        "  def __init__(self, num_features, num_classes):\n",
        "    self.num_features = num_features\n",
        "    self.num_classes = num_classes\n",
        "    self.theta_k = np.zeros(num_classes)\n",
        "    self.theta_j_k = np.zeros((num_classes, num_features))\n",
        "\n",
        "    self.accuracy = 0;\n",
        "\n",
        "  def train(self, X, Y, laplace_smoothing = True):\n",
        "    num_features = self.num_features\n",
        "    num_classes = self.num_classes\n",
        "\n",
        "    num_samples = X.shape[0]\n",
        "\n",
        "    class_frequency = np.zeros(num_classes)\n",
        "\n",
        "    # k denotes the class number\n",
        "    # j denotes the feature number\n",
        "    theta_k = np.zeros(num_classes)\n",
        "    theta_j_k = np.zeros((num_classes, num_features))\n",
        "\n",
        "    # find frequency of output class\n",
        "    for i in range (num_samples):\n",
        "       for j in range (num_classes):\n",
        "          class_index = int(Y[i])\n",
        "          class_frequency[class_index] += 1\n",
        "          break\n",
        "\n",
        "    # find P(Y = k)\n",
        "    for i in range (num_classes):\n",
        "      theta_k[i] = class_frequency[i] / num_samples\n",
        "\n",
        "    # find P(X=1|Y=k) = theta_j_k\n",
        "    # P(X=0|Y=k) = 1 - P(X=1|Y=k) = 1 - theta_j_k\n",
        "    for i in range (num_samples):\n",
        "      for j in range (num_features):\n",
        "        # FIXME: used to be X[i][0, j] until it suddenly broke? change for kfold\n",
        "        if (X[i][j] == 1):\n",
        "          class_index = int(Y[i])\n",
        "          theta_j_k[class_index, j] += 1\n",
        "\n",
        "    if laplace_smoothing:\n",
        "      for i in range (num_classes):\n",
        "        theta_j_k[i] = (theta_j_k[i] + 1) / (class_frequency[i] + 2)\n",
        "    else:\n",
        "      for i in range (num_classes):\n",
        "        theta_j_k[i] = theta_j_k[i] / class_frequency[i]\n",
        "\n",
        "    self.theta_k = theta_k\n",
        "    self.theta_j_k = theta_j_k\n",
        "\n",
        "  def predict(self, X):\n",
        "    num_features = self.num_features\n",
        "    num_classes = self.num_classes\n",
        "    theta_k = self.theta_k\n",
        "    theta_j_k = self.theta_j_k\n",
        "\n",
        "    num_samples = X.shape[0]\n",
        "\n",
        "    delta_k = np.zeros(num_classes)\n",
        "\n",
        "    output_labels_indexed = np.zeros(num_samples, dtype=int)\n",
        "\n",
        "    for i in range (num_samples):\n",
        "\n",
        "      # calculate the delta_k for each class, iterating over the features\n",
        "      for k in range (num_classes):\n",
        "        delta_k[k] = np.log(theta_k[k])\n",
        "        for j in range (num_features):\n",
        "          if (X[i][0,j] == 1):\n",
        "            delta_k[k] += np.log(theta_j_k[k][j])\n",
        "          elif (X[i][0,j] == 0):\n",
        "            delta_k[k] += np.log(1 - theta_j_k[k][j])\n",
        "\n",
        "      #find the class with the highest delta_k\n",
        "      max_delta_k_index = np.argmax(delta_k)\n",
        "      output_labels_indexed[i] = int(max_delta_k_index)\n",
        "\n",
        "    return output_labels_indexed"
      ],
      "metadata": {
        "id": "xFUFjRoyRArG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### main"
      ],
      "metadata": {
        "id": "QJuB1IHYsa0c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### kfold main\n"
      ],
      "metadata": {
        "id": "auFt597smEq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "\n",
        "scikit_classifiers = []\n",
        "\n",
        "scikit_accuracies = np.zeros(kf.get_n_splits())\n",
        "\n",
        "\n",
        "NB_classifiers = []\n",
        "output_indexed = np.array([None] * kf.get_n_splits())\n",
        "\n",
        "\n",
        "for i in range (kf.get_n_splits()):\n",
        "  # initialize class, train, and predict\n",
        "  NB = Naive_Bayes_Classifier(num_features=3000, num_classes=4)\n",
        "  NB_classifiers.append(NB)\n",
        "  NB_classifiers[i].train(X_train[i], Y_train[i])\n",
        "\n",
        "  CL = MultinomialNB()\n",
        "  scikit_classifiers.append(CL)\n",
        "  scikit_classifiers[i].fit(X_train[i], Y_train[i])\n",
        "\n",
        "  output_indexed[i] = (NB.predict(X_test[i]))\n",
        "  y_pred = scikit_classifiers[i].predict(np.asarray(X_test[i]))\n",
        "\n",
        "  NB_classifiers[i].accuracy = calculate_accuracy(output_indexed[i], Y_test[i])\n",
        "  scikit_accuracies[i] = calculate_accuracy(y_pred, Y_test[i])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VFWAxHa93b8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####"
      ],
      "metadata": {
        "id": "_FUwe7TbHJ5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracies \")\n",
        "print(\"--------------------\")\n",
        "highest_accuracy_index = 0\n",
        "highest_scikit_accuracy_index = 0\n",
        "\n",
        "for i in range(len(NB_classifiers)):\n",
        "  print(\"test \" + str(i) + \" : \" + str(NB_classifiers[i].accuracy))\n",
        "  print(\"scikit accuracy: \" + str(scikit_accuracies[i]))\n",
        "  if NB_classifiers[i].accuracy > NB_classifiers[highest_accuracy_index].accuracy:\n",
        "    highest_accuracy_index = i\n",
        "\n",
        "    if scikit_accuracies[i] > scikit_accuracies[highest_scikit_accuracy_index]:\n",
        "      highest_scikit_accuracy_index = i\n",
        "\n",
        "print(\"--------------------\")\n",
        "print(\"highest accuracy: \" + str(NB_classifiers[highest_accuracy_index].accuracy))\n",
        "\n",
        "print(\"--------------------\")\n",
        "print(\"highest scikit accuracy: \" + str(scikit_accuracies[highest_scikit_accuracy_index]))\n",
        "\n",
        "### these need to be reshuffled... thats why final predictions are low\n",
        "final_label = NB_classifiers[highest_accuracy_index].predict(input_data_x_b)\n",
        "final_scikit_label = scikit_classifiers[highest_scikit_accuracy_index].predict(np.asarray(input_data_x_b))\n",
        "print(\"final prediction using highest accuracy model\")\n",
        "print(\"for my model:\")\n",
        "print(calculate_accuracy(final_label, input_data_y_indexed))\n",
        "print(\"for scikit model:\")\n",
        "print(calculate_accuracy(final_scikit_label, input_data_y_indexed))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEAFBXa3ZcN6",
        "outputId": "b1200cf0-6052-4f18-95bb-804a02c01cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracies \n",
            "--------------------\n",
            "test 0 : 0.5571428571428572\n",
            "scikit accuracy: 0.4357142857142857\n",
            "test 1 : 0.5071428571428571\n",
            "scikit accuracy: 0.4714285714285714\n",
            "test 2 : 0.5071428571428571\n",
            "scikit accuracy: 0.42857142857142855\n",
            "test 3 : 0.5071428571428571\n",
            "scikit accuracy: 0.42857142857142855\n",
            "test 4 : 0.5142857142857142\n",
            "scikit accuracy: 0.42857142857142855\n",
            "test 5 : 0.5214285714285715\n",
            "scikit accuracy: 0.45714285714285713\n",
            "test 6 : 0.44285714285714284\n",
            "scikit accuracy: 0.4\n",
            "test 7 : 0.5071428571428571\n",
            "scikit accuracy: 0.45714285714285713\n",
            "test 8 : 0.5142857142857142\n",
            "scikit accuracy: 0.4\n",
            "test 9 : 0.4785714285714286\n",
            "scikit accuracy: 0.4785714285714286\n",
            "--------------------\n",
            "highest accuracy: 0.5571428571428572\n",
            "--------------------\n",
            "highest scikit accuracy: 0.4357142857142857\n",
            "final prediction using highest accuracy model\n",
            "for my model:\n",
            "0.24571428571428572\n",
            "for scikit model:\n",
            "0.14714285714285713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### test_train_split main"
      ],
      "metadata": {
        "id": "J43GCl1FmIMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  NB = Naive_Bayes_Classifier(num_features=3000, num_classes=4)\n",
        "  NB.train(X_train, Y_train)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZbtXyh_NmLQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  NB.latest_output_indexed = NB.predict(X_test, Y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeZbX-u0qpsF",
        "outputId": "1c921145-bb6f-4f2d-a87d-70f2ad4f72f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(140,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  NB.accuracy = calculate_accuracy(NB.latest_output_indexed, Y_test)\n",
        "  print(NB.accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-lmEIx_ngDt",
        "outputId": "556cca3a-005d-450d-c639-bbef9eb6ee6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.32857142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Outdated"
      ],
      "metadata": {
        "id": "ovQt8kl08ton"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # converts class names to integers to be used as indices\n",
        "# # takes in a list of class names and the numpy array Y\n",
        "# def class_name_to_index(class_names, Y):\n",
        "#     for i in range (Y.shape[0]):\n",
        "#         for j in range (class_names.shape[0]):\n",
        "#           if Y[i] == class_names[j]:\n",
        "#             Y[i] = j\n",
        "#             break\n",
        "#           # elif j == class_names.shape[0] - 1:\n",
        "#           #   print(Y[i])\n",
        "#           #   print(j)\n",
        "#           #   raise ValueError('unexpected class name in Y')\n",
        "#     return Y\n",
        "\n",
        "# # converts class index (i.e. integers) back to their class names\n",
        "# # takes in the same list of class names and the numpy array Y_integer\n",
        "# def index_to_class_name(class_names, Y_integer):\n",
        "#     for i in range (Y_integer.shape[0]):\n",
        "#         for j in range (class_names.shape[0]):\n",
        "#           if Y_integer[i] == j:\n",
        "#             Y_integer[i] = class_names[j]\n",
        "#             break\n",
        "#           elif j == class_names.shape[0] - 1:\n",
        "#             raise ValueError('unexpected class index in Y_integer')\n",
        "#     return Y_integer\n",
        "\n",
        "# for i in range (test_data_y.shape[0]):\n",
        "#   print(test_data_y[i])\n",
        "#   if test_data_y[i] == 'Toronto':\n",
        "#     Y_test[i] = 0\n",
        "#   elif test_data_y[i] == 'Montreal':\n",
        "#     Y_test[i] = 1\n",
        "#   elif test_data_y[i] == 'London':\n",
        "#     Y_test[i] = 2\n",
        "#   elif test_data_y[i] == 'Brussels':\n",
        "#     Y_test[i] = 3\n",
        "\n"
      ],
      "metadata": {
        "id": "JVr3Y5xO8vLV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}